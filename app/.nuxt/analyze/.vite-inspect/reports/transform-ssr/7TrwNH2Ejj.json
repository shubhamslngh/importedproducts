{
  "resolvedId": "/Users/shubhamsingh/namma/importedProds/node_modules/@apollo/client/cache/inmemory/inMemoryCache.js",
  "transforms": [
    {
      "name": "vite:load-fallback",
      "result": "import { __assign, __extends } from \"tslib\";\nimport { invariant } from \"../../utilities/globals/index.js\";\n// Make builtins like Map and Set safe to use with non-extensible objects.\nimport \"./fixPolyfills.js\";\nimport { wrap } from \"optimism\";\nimport { equal } from \"@wry/equality\";\nimport { ApolloCache } from \"../core/cache.js\";\nimport { MissingFieldError } from \"../core/types/common.js\";\nimport { addTypenameToDocument, isReference, DocumentTransform, canonicalStringify, print, cacheSizes, } from \"../../utilities/index.js\";\nimport { StoreReader } from \"./readFromStore.js\";\nimport { StoreWriter } from \"./writeToStore.js\";\nimport { EntityStore, supportsResultCaching } from \"./entityStore.js\";\nimport { makeVar, forgetCache, recallCache } from \"./reactiveVars.js\";\nimport { Policies } from \"./policies.js\";\nimport { hasOwn, normalizeConfig, shouldCanonizeResults } from \"./helpers.js\";\nimport { getInMemoryCacheMemoryInternals } from \"../../utilities/caching/getMemoryInternals.js\";\nvar InMemoryCache = /** @class */ (function (_super) {\n    __extends(InMemoryCache, _super);\n    function InMemoryCache(config) {\n        if (config === void 0) { config = {}; }\n        var _this = _super.call(this) || this;\n        _this.watches = new Set();\n        _this.addTypenameTransform = new DocumentTransform(addTypenameToDocument);\n        // Override the default value, since InMemoryCache result objects are frozen\n        // in development and expected to remain logically immutable in production.\n        _this.assumeImmutableResults = true;\n        _this.makeVar = makeVar;\n        _this.txCount = 0;\n        _this.config = normalizeConfig(config);\n        _this.addTypename = !!_this.config.addTypename;\n        _this.policies = new Policies({\n            cache: _this,\n            dataIdFromObject: _this.config.dataIdFromObject,\n            possibleTypes: _this.config.possibleTypes,\n            typePolicies: _this.config.typePolicies,\n        });\n        _this.init();\n        return _this;\n    }\n    InMemoryCache.prototype.init = function () {\n        // Passing { resultCaching: false } in the InMemoryCache constructor options\n        // will completely disable dependency tracking, which will improve memory\n        // usage but worsen the performance of repeated reads.\n        var rootStore = (this.data = new EntityStore.Root({\n            policies: this.policies,\n            resultCaching: this.config.resultCaching,\n        }));\n        // When no optimistic writes are currently active, cache.optimisticData ===\n        // cache.data, so there are no additional layers on top of the actual data.\n        // When an optimistic update happens, this.optimisticData will become a\n        // linked list of EntityStore Layer objects that terminates with the\n        // original this.data cache object.\n        this.optimisticData = rootStore.stump;\n        this.resetResultCache();\n    };\n    InMemoryCache.prototype.resetResultCache = function (resetResultIdentities) {\n        var _this = this;\n        var previousReader = this.storeReader;\n        var fragments = this.config.fragments;\n        // The StoreWriter is mostly stateless and so doesn't really need to be\n        // reset, but it does need to have its writer.storeReader reference updated,\n        // so it's simpler to update this.storeWriter as well.\n        this.storeWriter = new StoreWriter(this, (this.storeReader = new StoreReader({\n            cache: this,\n            addTypename: this.addTypename,\n            resultCacheMaxSize: this.config.resultCacheMaxSize,\n            canonizeResults: shouldCanonizeResults(this.config),\n            canon: resetResultIdentities ? void 0 : (previousReader && previousReader.canon),\n            fragments: fragments,\n        })), fragments);\n        this.maybeBroadcastWatch = wrap(function (c, options) {\n            return _this.broadcastWatch(c, options);\n        }, {\n            max: this.config.resultCacheMaxSize ||\n                cacheSizes[\"inMemoryCache.maybeBroadcastWatch\"] ||\n                5000 /* defaultCacheSizes[\"inMemoryCache.maybeBroadcastWatch\"] */,\n            makeCacheKey: function (c) {\n                // Return a cache key (thus enabling result caching) only if we're\n                // currently using a data store that can track cache dependencies.\n                var store = c.optimistic ? _this.optimisticData : _this.data;\n                if (supportsResultCaching(store)) {\n                    var optimistic = c.optimistic, id = c.id, variables = c.variables;\n                    return store.makeCacheKey(c.query, \n                    // Different watches can have the same query, optimistic\n                    // status, rootId, and variables, but if their callbacks are\n                    // different, the (identical) result needs to be delivered to\n                    // each distinct callback. The easiest way to achieve that\n                    // separation is to include c.callback in the cache key for\n                    // maybeBroadcastWatch calls. See issue #5733.\n                    c.callback, canonicalStringify({ optimistic: optimistic, id: id, variables: variables }));\n                }\n            },\n        });\n        // Since we have thrown away all the cached functions that depend on the\n        // CacheGroup dependencies maintained by EntityStore, we should also reset\n        // all CacheGroup dependency information.\n        new Set([this.data.group, this.optimisticData.group]).forEach(function (group) {\n            return group.resetCaching();\n        });\n    };\n    InMemoryCache.prototype.restore = function (data) {\n        this.init();\n        // Since calling this.init() discards/replaces the entire StoreReader, along\n        // with the result caches it maintains, this.data.replace(data) won't have\n        // to bother deleting the old data.\n        if (data)\n            this.data.replace(data);\n        return this;\n    };\n    InMemoryCache.prototype.extract = function (optimistic) {\n        if (optimistic === void 0) { optimistic = false; }\n        return (optimistic ? this.optimisticData : this.data).extract();\n    };\n    InMemoryCache.prototype.read = function (options) {\n        var \n        // Since read returns data or null, without any additional metadata\n        // about whether/where there might have been missing fields, the\n        // default behavior cannot be returnPartialData = true (like it is\n        // for the diff method), since defaulting to true would violate the\n        // integrity of the T in the return type. However, partial data may\n        // be useful in some cases, so returnPartialData:true may be\n        // specified explicitly.\n        _a = options.returnPartialData, \n        // Since read returns data or null, without any additional metadata\n        // about whether/where there might have been missing fields, the\n        // default behavior cannot be returnPartialData = true (like it is\n        // for the diff method), since defaulting to true would violate the\n        // integrity of the T in the return type. However, partial data may\n        // be useful in some cases, so returnPartialData:true may be\n        // specified explicitly.\n        returnPartialData = _a === void 0 ? false : _a;\n        try {\n            return (this.storeReader.diffQueryAgainstStore(__assign(__assign({}, options), { store: options.optimistic ? this.optimisticData : this.data, config: this.config, returnPartialData: returnPartialData })).result || null);\n        }\n        catch (e) {\n            if (e instanceof MissingFieldError) {\n                // Swallow MissingFieldError and return null, so callers do not need to\n                // worry about catching \"normal\" exceptions resulting from incomplete\n                // cache data. Unexpected errors will be re-thrown. If you need more\n                // information about which fields were missing, use cache.diff instead,\n                // and examine diffResult.missing.\n                return null;\n            }\n            throw e;\n        }\n    };\n    InMemoryCache.prototype.write = function (options) {\n        try {\n            ++this.txCount;\n            return this.storeWriter.writeToStore(this.data, options);\n        }\n        finally {\n            if (!--this.txCount && options.broadcast !== false) {\n                this.broadcastWatches();\n            }\n        }\n    };\n    InMemoryCache.prototype.modify = function (options) {\n        if (hasOwn.call(options, \"id\") && !options.id) {\n            // To my knowledge, TypeScript does not currently provide a way to\n            // enforce that an optional property?:type must *not* be undefined\n            // when present. That ability would be useful here, because we want\n            // options.id to default to ROOT_QUERY only when no options.id was\n            // provided. If the caller attempts to pass options.id with a\n            // falsy/undefined value (perhaps because cache.identify failed), we\n            // should not assume the goal was to modify the ROOT_QUERY object.\n            // We could throw, but it seems natural to return false to indicate\n            // that nothing was modified.\n            return false;\n        }\n        var store = ((options.optimistic) // Defaults to false.\n        ) ?\n            this.optimisticData\n            : this.data;\n        try {\n            ++this.txCount;\n            return store.modify(options.id || \"ROOT_QUERY\", options.fields);\n        }\n        finally {\n            if (!--this.txCount && options.broadcast !== false) {\n                this.broadcastWatches();\n            }\n        }\n    };\n    InMemoryCache.prototype.diff = function (options) {\n        return this.storeReader.diffQueryAgainstStore(__assign(__assign({}, options), { store: options.optimistic ? this.optimisticData : this.data, rootId: options.id || \"ROOT_QUERY\", config: this.config }));\n    };\n    InMemoryCache.prototype.watch = function (watch) {\n        var _this = this;\n        if (!this.watches.size) {\n            // In case we previously called forgetCache(this) because\n            // this.watches became empty (see below), reattach this cache to any\n            // reactive variables on which it previously depended. It might seem\n            // paradoxical that we're able to recall something we supposedly\n            // forgot, but the point of calling forgetCache(this) is to silence\n            // useless broadcasts while this.watches is empty, and to allow the\n            // cache to be garbage collected. If, however, we manage to call\n            // recallCache(this) here, this cache object must not have been\n            // garbage collected yet, and should resume receiving updates from\n            // reactive variables, now that it has a watcher to notify.\n            recallCache(this);\n        }\n        this.watches.add(watch);\n        if (watch.immediate) {\n            this.maybeBroadcastWatch(watch);\n        }\n        return function () {\n            // Once we remove the last watch from this.watches, cache.broadcastWatches\n            // no longer does anything, so we preemptively tell the reactive variable\n            // system to exclude this cache from future broadcasts.\n            if (_this.watches.delete(watch) && !_this.watches.size) {\n                forgetCache(_this);\n            }\n            // Remove this watch from the LRU cache managed by the\n            // maybeBroadcastWatch OptimisticWrapperFunction, to prevent memory\n            // leaks involving the closure of watch.callback.\n            _this.maybeBroadcastWatch.forget(watch);\n        };\n    };\n    InMemoryCache.prototype.gc = function (options) {\n        var _a;\n        canonicalStringify.reset();\n        print.reset();\n        this.addTypenameTransform.resetCache();\n        (_a = this.config.fragments) === null || _a === void 0 ? void 0 : _a.resetCaches();\n        var ids = this.optimisticData.gc();\n        if (options && !this.txCount) {\n            if (options.resetResultCache) {\n                this.resetResultCache(options.resetResultIdentities);\n            }\n            else if (options.resetResultIdentities) {\n                this.storeReader.resetCanon();\n            }\n        }\n        return ids;\n    };\n    // Call this method to ensure the given root ID remains in the cache after\n    // garbage collection, along with its transitive child entities. Note that\n    // the cache automatically retains all directly written entities. By default,\n    // the retainment persists after optimistic updates are removed. Pass true\n    // for the optimistic argument if you would prefer for the retainment to be\n    // discarded when the top-most optimistic layer is removed. Returns the\n    // resulting (non-negative) retainment count.\n    InMemoryCache.prototype.retain = function (rootId, optimistic) {\n        return (optimistic ? this.optimisticData : this.data).retain(rootId);\n    };\n    // Call this method to undo the effect of the retain method, above. Once the\n    // retainment count falls to zero, the given ID will no longer be preserved\n    // during garbage collection, though it may still be preserved by other safe\n    // entities that refer to it. Returns the resulting (non-negative) retainment\n    // count, in case that's useful.\n    InMemoryCache.prototype.release = function (rootId, optimistic) {\n        return (optimistic ? this.optimisticData : this.data).release(rootId);\n    };\n    // Returns the canonical ID for a given StoreObject, obeying typePolicies\n    // and keyFields (and dataIdFromObject, if you still use that). At minimum,\n    // the object must contain a __typename and any primary key fields required\n    // to identify entities of that type. If you pass a query result object, be\n    // sure that none of the primary key fields have been renamed by aliasing.\n    // If you pass a Reference object, its __ref ID string will be returned.\n    InMemoryCache.prototype.identify = function (object) {\n        if (isReference(object))\n            return object.__ref;\n        try {\n            return this.policies.identify(object)[0];\n        }\n        catch (e) {\n            globalThis.__DEV__ !== false && invariant.warn(e);\n        }\n    };\n    InMemoryCache.prototype.evict = function (options) {\n        if (!options.id) {\n            if (hasOwn.call(options, \"id\")) {\n                // See comment in modify method about why we return false when\n                // options.id exists but is falsy/undefined.\n                return false;\n            }\n            options = __assign(__assign({}, options), { id: \"ROOT_QUERY\" });\n        }\n        try {\n            // It's unlikely that the eviction will end up invoking any other\n            // cache update operations while it's running, but {in,de}crementing\n            // this.txCount still seems like a good idea, for uniformity with\n            // the other update methods.\n            ++this.txCount;\n            // Pass this.data as a limit on the depth of the eviction, so evictions\n            // during optimistic updates (when this.data is temporarily set equal to\n            // this.optimisticData) do not escape their optimistic Layer.\n            return this.optimisticData.evict(options, this.data);\n        }\n        finally {\n            if (!--this.txCount && options.broadcast !== false) {\n                this.broadcastWatches();\n            }\n        }\n    };\n    InMemoryCache.prototype.reset = function (options) {\n        var _this = this;\n        this.init();\n        canonicalStringify.reset();\n        if (options && options.discardWatches) {\n            // Similar to what happens in the unsubscribe function returned by\n            // cache.watch, applied to all current watches.\n            this.watches.forEach(function (watch) { return _this.maybeBroadcastWatch.forget(watch); });\n            this.watches.clear();\n            forgetCache(this);\n        }\n        else {\n            // Calling this.init() above unblocks all maybeBroadcastWatch caching, so\n            // this.broadcastWatches() triggers a broadcast to every current watcher\n            // (letting them know their data is now missing). This default behavior is\n            // convenient because it means the watches do not have to be manually\n            // reestablished after resetting the cache. To prevent this broadcast and\n            // cancel all watches, pass true for options.discardWatches.\n            this.broadcastWatches();\n        }\n        return Promise.resolve();\n    };\n    InMemoryCache.prototype.removeOptimistic = function (idToRemove) {\n        var newOptimisticData = this.optimisticData.removeLayer(idToRemove);\n        if (newOptimisticData !== this.optimisticData) {\n            this.optimisticData = newOptimisticData;\n            this.broadcastWatches();\n        }\n    };\n    InMemoryCache.prototype.batch = function (options) {\n        var _this = this;\n        var update = options.update, _a = options.optimistic, optimistic = _a === void 0 ? true : _a, removeOptimistic = options.removeOptimistic, onWatchUpdated = options.onWatchUpdated;\n        var updateResult;\n        var perform = function (layer) {\n            var _a = _this, data = _a.data, optimisticData = _a.optimisticData;\n            ++_this.txCount;\n            if (layer) {\n                _this.data = _this.optimisticData = layer;\n            }\n            try {\n                return (updateResult = update(_this));\n            }\n            finally {\n                --_this.txCount;\n                _this.data = data;\n                _this.optimisticData = optimisticData;\n            }\n        };\n        var alreadyDirty = new Set();\n        if (onWatchUpdated && !this.txCount) {\n            // If an options.onWatchUpdated callback is provided, we want to call it\n            // with only the Cache.WatchOptions objects affected by options.update,\n            // but there might be dirty watchers already waiting to be broadcast that\n            // have nothing to do with the update. To prevent including those watchers\n            // in the post-update broadcast, we perform this initial broadcast to\n            // collect the dirty watchers, so we can re-dirty them later, after the\n            // post-update broadcast, allowing them to receive their pending\n            // broadcasts the next time broadcastWatches is called, just as they would\n            // if we never called cache.batch.\n            this.broadcastWatches(__assign(__assign({}, options), { onWatchUpdated: function (watch) {\n                    alreadyDirty.add(watch);\n                    return false;\n                } }));\n        }\n        if (typeof optimistic === \"string\") {\n            // Note that there can be multiple layers with the same optimistic ID.\n            // When removeOptimistic(id) is called for that id, all matching layers\n            // will be removed, and the remaining layers will be reapplied.\n            this.optimisticData = this.optimisticData.addLayer(optimistic, perform);\n        }\n        else if (optimistic === false) {\n            // Ensure both this.data and this.optimisticData refer to the root\n            // (non-optimistic) layer of the cache during the update. Note that\n            // this.data could be a Layer if we are currently executing an optimistic\n            // update function, but otherwise will always be an EntityStore.Root\n            // instance.\n            perform(this.data);\n        }\n        else {\n            // Otherwise, leave this.data and this.optimisticData unchanged and run\n            // the update with broadcast batching.\n            perform();\n        }\n        if (typeof removeOptimistic === \"string\") {\n            this.optimisticData = this.optimisticData.removeLayer(removeOptimistic);\n        }\n        // Note: if this.txCount > 0, then alreadyDirty.size === 0, so this code\n        // takes the else branch and calls this.broadcastWatches(options), which\n        // does nothing when this.txCount > 0.\n        if (onWatchUpdated && alreadyDirty.size) {\n            this.broadcastWatches(__assign(__assign({}, options), { onWatchUpdated: function (watch, diff) {\n                    var result = onWatchUpdated.call(this, watch, diff);\n                    if (result !== false) {\n                        // Since onWatchUpdated did not return false, this diff is\n                        // about to be broadcast to watch.callback, so we don't need\n                        // to re-dirty it with the other alreadyDirty watches below.\n                        alreadyDirty.delete(watch);\n                    }\n                    return result;\n                } }));\n            // Silently re-dirty any watches that were already dirty before the update\n            // was performed, and were not broadcast just now.\n            if (alreadyDirty.size) {\n                alreadyDirty.forEach(function (watch) { return _this.maybeBroadcastWatch.dirty(watch); });\n            }\n        }\n        else {\n            // If alreadyDirty is empty or we don't have an onWatchUpdated\n            // function, we don't need to go to the trouble of wrapping\n            // options.onWatchUpdated.\n            this.broadcastWatches(options);\n        }\n        return updateResult;\n    };\n    InMemoryCache.prototype.performTransaction = function (update, optimisticId) {\n        return this.batch({\n            update: update,\n            optimistic: optimisticId || optimisticId !== null,\n        });\n    };\n    InMemoryCache.prototype.transformDocument = function (document) {\n        return this.addTypenameToDocument(this.addFragmentsToDocument(document));\n    };\n    InMemoryCache.prototype.broadcastWatches = function (options) {\n        var _this = this;\n        if (!this.txCount) {\n            this.watches.forEach(function (c) { return _this.maybeBroadcastWatch(c, options); });\n        }\n    };\n    InMemoryCache.prototype.addFragmentsToDocument = function (document) {\n        var fragments = this.config.fragments;\n        return fragments ? fragments.transform(document) : document;\n    };\n    InMemoryCache.prototype.addTypenameToDocument = function (document) {\n        if (this.addTypename) {\n            return this.addTypenameTransform.transformDocument(document);\n        }\n        return document;\n    };\n    // This method is wrapped by maybeBroadcastWatch, which is called by\n    // broadcastWatches, so that we compute and broadcast results only when\n    // the data that would be broadcast might have changed. It would be\n    // simpler to check for changes after recomputing a result but before\n    // broadcasting it, but this wrapping approach allows us to skip both\n    // the recomputation and the broadcast, in most cases.\n    InMemoryCache.prototype.broadcastWatch = function (c, options) {\n        var lastDiff = c.lastDiff;\n        // Both WatchOptions and DiffOptions extend ReadOptions, and DiffOptions\n        // currently requires no additional properties, so we can use c (a\n        // WatchOptions object) as DiffOptions, without having to allocate a new\n        // object, and without having to enumerate the relevant properties (query,\n        // variables, etc.) explicitly. There will be some additional properties\n        // (lastDiff, callback, etc.), but cache.diff ignores them.\n        var diff = this.diff(c);\n        if (options) {\n            if (c.optimistic && typeof options.optimistic === \"string\") {\n                diff.fromOptimisticTransaction = true;\n            }\n            if (options.onWatchUpdated &&\n                options.onWatchUpdated.call(this, c, diff, lastDiff) === false) {\n                // Returning false from the onWatchUpdated callback will prevent\n                // calling c.callback(diff) for this watcher.\n                return;\n            }\n        }\n        if (!lastDiff || !equal(lastDiff.result, diff.result)) {\n            c.callback((c.lastDiff = diff), lastDiff);\n        }\n    };\n    return InMemoryCache;\n}(ApolloCache));\nexport { InMemoryCache };\nif (globalThis.__DEV__ !== false) {\n    InMemoryCache.prototype.getMemoryInternals = getInMemoryCacheMemoryInternals;\n}\n//# sourceMappingURL=inMemoryCache.js.map",
      "start": 1713304786750,
      "end": 1713304786756,
      "sourcemaps": null
    },
    {
      "name": "nuxt:layer-aliasing",
      "start": 1713304786756,
      "end": 1713304786756,
      "order": "pre"
    },
    {
      "name": "nuxt:layer-aliasing",
      "start": 1713304786756,
      "end": 1713304786756,
      "order": "pre"
    },
    {
      "name": "nuxt:server-devonly:transform",
      "start": 1713304786756,
      "end": 1713304786756,
      "order": "pre"
    },
    {
      "name": "nuxt:server-devonly:transform",
      "start": 1713304786756,
      "end": 1713304786756,
      "order": "pre"
    },
    {
      "name": "content-slot",
      "start": 1713304786756,
      "end": 1713304786756,
      "order": "pre"
    },
    {
      "name": "content-slot",
      "start": 1713304786756,
      "end": 1713304786756,
      "order": "pre"
    },
    {
      "name": "nuxt:client-fallback-auto-id",
      "start": 1713304786756,
      "end": 1713304786756,
      "order": "pre"
    },
    {
      "name": "vite:css",
      "start": 1713304786756,
      "end": 1713304786756,
      "order": "normal"
    },
    {
      "name": "vite:esbuild",
      "start": 1713304786756,
      "end": 1713304786756,
      "order": "normal"
    },
    {
      "name": "vite:json",
      "start": 1713304786756,
      "end": 1713304786756,
      "order": "normal"
    },
    {
      "name": "vite:worker",
      "start": 1713304786757,
      "end": 1713304786757,
      "order": "normal"
    },
    {
      "name": "vite:vue",
      "start": 1713304786757,
      "end": 1713304786757,
      "order": "normal"
    },
    {
      "name": "vite:vue-jsx",
      "start": 1713304786757,
      "end": 1713304786757,
      "order": "normal"
    },
    {
      "name": "replace",
      "start": 1713304786757,
      "end": 1713304786757,
      "order": "normal"
    },
    {
      "name": "replace",
      "start": 1713304786757,
      "end": 1713304786757,
      "order": "normal"
    },
    {
      "name": "nuxt:remove-plugin-metadata",
      "start": 1713304786757,
      "end": 1713304786757,
      "order": "normal"
    },
    {
      "name": "nuxt:remove-plugin-metadata",
      "start": 1713304786757,
      "end": 1713304786757,
      "order": "normal"
    },
    {
      "name": "graphql",
      "start": 1713304786757,
      "end": 1713304786757,
      "order": "normal"
    },
    {
      "name": "nuxt:components:imports",
      "start": 1713304786757,
      "end": 1713304786757,
      "order": "normal"
    },
    {
      "name": "replace",
      "start": 1713304786757,
      "end": 1713304786757,
      "order": "normal"
    },
    {
      "name": "ssr-styles",
      "start": 1713304786757,
      "end": 1713304786757,
      "order": "normal"
    },
    {
      "name": "vite:define",
      "result": "import { __assign, __extends } from \"tslib\";\nimport { invariant } from \"../../utilities/globals/index.js\";\nimport \"./fixPolyfills.js\";\nimport { wrap } from \"optimism\";\nimport { equal } from \"@wry/equality\";\nimport { ApolloCache } from \"../core/cache.js\";\nimport { MissingFieldError } from \"../core/types/common.js\";\nimport { addTypenameToDocument, isReference, DocumentTransform, canonicalStringify, print, cacheSizes } from \"../../utilities/index.js\";\nimport { StoreReader } from \"./readFromStore.js\";\nimport { StoreWriter } from \"./writeToStore.js\";\nimport { EntityStore, supportsResultCaching } from \"./entityStore.js\";\nimport { makeVar, forgetCache, recallCache } from \"./reactiveVars.js\";\nimport { Policies } from \"./policies.js\";\nimport { hasOwn, normalizeConfig, shouldCanonizeResults } from \"./helpers.js\";\nimport { getInMemoryCacheMemoryInternals } from \"../../utilities/caching/getMemoryInternals.js\";\nvar InMemoryCache = (\n  /** @class */\n  function(_super) {\n    __extends(InMemoryCache2, _super);\n    function InMemoryCache2(config) {\n      if (config === void 0) {\n        config = {};\n      }\n      var _this = _super.call(this) || this;\n      _this.watches = /* @__PURE__ */ new Set();\n      _this.addTypenameTransform = new DocumentTransform(addTypenameToDocument);\n      _this.assumeImmutableResults = true;\n      _this.makeVar = makeVar;\n      _this.txCount = 0;\n      _this.config = normalizeConfig(config);\n      _this.addTypename = !!_this.config.addTypename;\n      _this.policies = new Policies({\n        cache: _this,\n        dataIdFromObject: _this.config.dataIdFromObject,\n        possibleTypes: _this.config.possibleTypes,\n        typePolicies: _this.config.typePolicies\n      });\n      _this.init();\n      return _this;\n    }\n    InMemoryCache2.prototype.init = function() {\n      var rootStore = this.data = new EntityStore.Root({\n        policies: this.policies,\n        resultCaching: this.config.resultCaching\n      });\n      this.optimisticData = rootStore.stump;\n      this.resetResultCache();\n    };\n    InMemoryCache2.prototype.resetResultCache = function(resetResultIdentities) {\n      var _this = this;\n      var previousReader = this.storeReader;\n      var fragments = this.config.fragments;\n      this.storeWriter = new StoreWriter(this, this.storeReader = new StoreReader({\n        cache: this,\n        addTypename: this.addTypename,\n        resultCacheMaxSize: this.config.resultCacheMaxSize,\n        canonizeResults: shouldCanonizeResults(this.config),\n        canon: resetResultIdentities ? void 0 : previousReader && previousReader.canon,\n        fragments\n      }), fragments);\n      this.maybeBroadcastWatch = wrap(function(c, options) {\n        return _this.broadcastWatch(c, options);\n      }, {\n        max: this.config.resultCacheMaxSize || cacheSizes[\"inMemoryCache.maybeBroadcastWatch\"] || 5e3,\n        makeCacheKey: function(c) {\n          var store = c.optimistic ? _this.optimisticData : _this.data;\n          if (supportsResultCaching(store)) {\n            var optimistic = c.optimistic, id = c.id, variables = c.variables;\n            return store.makeCacheKey(\n              c.query,\n              // Different watches can have the same query, optimistic\n              // status, rootId, and variables, but if their callbacks are\n              // different, the (identical) result needs to be delivered to\n              // each distinct callback. The easiest way to achieve that\n              // separation is to include c.callback in the cache key for\n              // maybeBroadcastWatch calls. See issue #5733.\n              c.callback,\n              canonicalStringify({ optimistic, id, variables })\n            );\n          }\n        }\n      });\n      (/* @__PURE__ */ new Set([this.data.group, this.optimisticData.group])).forEach(function(group) {\n        return group.resetCaching();\n      });\n    };\n    InMemoryCache2.prototype.restore = function(data) {\n      this.init();\n      if (data)\n        this.data.replace(data);\n      return this;\n    };\n    InMemoryCache2.prototype.extract = function(optimistic) {\n      if (optimistic === void 0) {\n        optimistic = false;\n      }\n      return (optimistic ? this.optimisticData : this.data).extract();\n    };\n    InMemoryCache2.prototype.read = function(options) {\n      var _a = options.returnPartialData, returnPartialData = _a === void 0 ? false : _a;\n      try {\n        return this.storeReader.diffQueryAgainstStore(__assign(__assign({}, options), { store: options.optimistic ? this.optimisticData : this.data, config: this.config, returnPartialData })).result || null;\n      } catch (e) {\n        if (e instanceof MissingFieldError) {\n          return null;\n        }\n        throw e;\n      }\n    };\n    InMemoryCache2.prototype.write = function(options) {\n      try {\n        ++this.txCount;\n        return this.storeWriter.writeToStore(this.data, options);\n      } finally {\n        if (!--this.txCount && options.broadcast !== false) {\n          this.broadcastWatches();\n        }\n      }\n    };\n    InMemoryCache2.prototype.modify = function(options) {\n      if (hasOwn.call(options, \"id\") && !options.id) {\n        return false;\n      }\n      var store = options.optimistic ? this.optimisticData : this.data;\n      try {\n        ++this.txCount;\n        return store.modify(options.id || \"ROOT_QUERY\", options.fields);\n      } finally {\n        if (!--this.txCount && options.broadcast !== false) {\n          this.broadcastWatches();\n        }\n      }\n    };\n    InMemoryCache2.prototype.diff = function(options) {\n      return this.storeReader.diffQueryAgainstStore(__assign(__assign({}, options), { store: options.optimistic ? this.optimisticData : this.data, rootId: options.id || \"ROOT_QUERY\", config: this.config }));\n    };\n    InMemoryCache2.prototype.watch = function(watch) {\n      var _this = this;\n      if (!this.watches.size) {\n        recallCache(this);\n      }\n      this.watches.add(watch);\n      if (watch.immediate) {\n        this.maybeBroadcastWatch(watch);\n      }\n      return function() {\n        if (_this.watches.delete(watch) && !_this.watches.size) {\n          forgetCache(_this);\n        }\n        _this.maybeBroadcastWatch.forget(watch);\n      };\n    };\n    InMemoryCache2.prototype.gc = function(options) {\n      var _a;\n      canonicalStringify.reset();\n      print.reset();\n      this.addTypenameTransform.resetCache();\n      (_a = this.config.fragments) === null || _a === void 0 ? void 0 : _a.resetCaches();\n      var ids = this.optimisticData.gc();\n      if (options && !this.txCount) {\n        if (options.resetResultCache) {\n          this.resetResultCache(options.resetResultIdentities);\n        } else if (options.resetResultIdentities) {\n          this.storeReader.resetCanon();\n        }\n      }\n      return ids;\n    };\n    InMemoryCache2.prototype.retain = function(rootId, optimistic) {\n      return (optimistic ? this.optimisticData : this.data).retain(rootId);\n    };\n    InMemoryCache2.prototype.release = function(rootId, optimistic) {\n      return (optimistic ? this.optimisticData : this.data).release(rootId);\n    };\n    InMemoryCache2.prototype.identify = function(object) {\n      if (isReference(object))\n        return object.__ref;\n      try {\n        return this.policies.identify(object)[0];\n      } catch (e) {\n        globalThis.__DEV__ !== false && invariant.warn(e);\n      }\n    };\n    InMemoryCache2.prototype.evict = function(options) {\n      if (!options.id) {\n        if (hasOwn.call(options, \"id\")) {\n          return false;\n        }\n        options = __assign(__assign({}, options), { id: \"ROOT_QUERY\" });\n      }\n      try {\n        ++this.txCount;\n        return this.optimisticData.evict(options, this.data);\n      } finally {\n        if (!--this.txCount && options.broadcast !== false) {\n          this.broadcastWatches();\n        }\n      }\n    };\n    InMemoryCache2.prototype.reset = function(options) {\n      var _this = this;\n      this.init();\n      canonicalStringify.reset();\n      if (options && options.discardWatches) {\n        this.watches.forEach(function(watch) {\n          return _this.maybeBroadcastWatch.forget(watch);\n        });\n        this.watches.clear();\n        forgetCache(this);\n      } else {\n        this.broadcastWatches();\n      }\n      return Promise.resolve();\n    };\n    InMemoryCache2.prototype.removeOptimistic = function(idToRemove) {\n      var newOptimisticData = this.optimisticData.removeLayer(idToRemove);\n      if (newOptimisticData !== this.optimisticData) {\n        this.optimisticData = newOptimisticData;\n        this.broadcastWatches();\n      }\n    };\n    InMemoryCache2.prototype.batch = function(options) {\n      var _this = this;\n      var update = options.update, _a = options.optimistic, optimistic = _a === void 0 ? true : _a, removeOptimistic = options.removeOptimistic, onWatchUpdated = options.onWatchUpdated;\n      var updateResult;\n      var perform = function(layer) {\n        var _a2 = _this, data = _a2.data, optimisticData = _a2.optimisticData;\n        ++_this.txCount;\n        if (layer) {\n          _this.data = _this.optimisticData = layer;\n        }\n        try {\n          return updateResult = update(_this);\n        } finally {\n          --_this.txCount;\n          _this.data = data;\n          _this.optimisticData = optimisticData;\n        }\n      };\n      var alreadyDirty = /* @__PURE__ */ new Set();\n      if (onWatchUpdated && !this.txCount) {\n        this.broadcastWatches(__assign(__assign({}, options), { onWatchUpdated: function(watch) {\n          alreadyDirty.add(watch);\n          return false;\n        } }));\n      }\n      if (typeof optimistic === \"string\") {\n        this.optimisticData = this.optimisticData.addLayer(optimistic, perform);\n      } else if (optimistic === false) {\n        perform(this.data);\n      } else {\n        perform();\n      }\n      if (typeof removeOptimistic === \"string\") {\n        this.optimisticData = this.optimisticData.removeLayer(removeOptimistic);\n      }\n      if (onWatchUpdated && alreadyDirty.size) {\n        this.broadcastWatches(__assign(__assign({}, options), { onWatchUpdated: function(watch, diff) {\n          var result = onWatchUpdated.call(this, watch, diff);\n          if (result !== false) {\n            alreadyDirty.delete(watch);\n          }\n          return result;\n        } }));\n        if (alreadyDirty.size) {\n          alreadyDirty.forEach(function(watch) {\n            return _this.maybeBroadcastWatch.dirty(watch);\n          });\n        }\n      } else {\n        this.broadcastWatches(options);\n      }\n      return updateResult;\n    };\n    InMemoryCache2.prototype.performTransaction = function(update, optimisticId) {\n      return this.batch({\n        update,\n        optimistic: optimisticId || optimisticId !== null\n      });\n    };\n    InMemoryCache2.prototype.transformDocument = function(document) {\n      return this.addTypenameToDocument(this.addFragmentsToDocument(document));\n    };\n    InMemoryCache2.prototype.broadcastWatches = function(options) {\n      var _this = this;\n      if (!this.txCount) {\n        this.watches.forEach(function(c) {\n          return _this.maybeBroadcastWatch(c, options);\n        });\n      }\n    };\n    InMemoryCache2.prototype.addFragmentsToDocument = function(document) {\n      var fragments = this.config.fragments;\n      return fragments ? fragments.transform(document) : document;\n    };\n    InMemoryCache2.prototype.addTypenameToDocument = function(document) {\n      if (this.addTypename) {\n        return this.addTypenameTransform.transformDocument(document);\n      }\n      return document;\n    };\n    InMemoryCache2.prototype.broadcastWatch = function(c, options) {\n      var lastDiff = c.lastDiff;\n      var diff = this.diff(c);\n      if (options) {\n        if (c.optimistic && typeof options.optimistic === \"string\") {\n          diff.fromOptimisticTransaction = true;\n        }\n        if (options.onWatchUpdated && options.onWatchUpdated.call(this, c, diff, lastDiff) === false) {\n          return;\n        }\n      }\n      if (!lastDiff || !equal(lastDiff.result, diff.result)) {\n        c.callback(c.lastDiff = diff, lastDiff);\n      }\n    };\n    return InMemoryCache2;\n  }(ApolloCache)\n);\nexport { InMemoryCache };\nif (globalThis.__DEV__ !== false) {\n  InMemoryCache.prototype.getMemoryInternals = getInMemoryCacheMemoryInternals;\n}\n",
      "start": 1713304786757,
      "end": 1713304787101,
      "order": "normal",
      "sourcemaps": "{\n  \"version\": 3,\n  \"sources\": [\"/Users/shubhamsingh/namma/importedProds/node_modules/@apollo/client/cache/inmemory/inMemoryCache.js\"],\n  \"sourcesContent\": [\"import { __assign, __extends } from \\\"tslib\\\";\\nimport { invariant } from \\\"../../utilities/globals/index.js\\\";\\n// Make builtins like Map and Set safe to use with non-extensible objects.\\nimport \\\"./fixPolyfills.js\\\";\\nimport { wrap } from \\\"optimism\\\";\\nimport { equal } from \\\"@wry/equality\\\";\\nimport { ApolloCache } from \\\"../core/cache.js\\\";\\nimport { MissingFieldError } from \\\"../core/types/common.js\\\";\\nimport { addTypenameToDocument, isReference, DocumentTransform, canonicalStringify, print, cacheSizes, } from \\\"../../utilities/index.js\\\";\\nimport { StoreReader } from \\\"./readFromStore.js\\\";\\nimport { StoreWriter } from \\\"./writeToStore.js\\\";\\nimport { EntityStore, supportsResultCaching } from \\\"./entityStore.js\\\";\\nimport { makeVar, forgetCache, recallCache } from \\\"./reactiveVars.js\\\";\\nimport { Policies } from \\\"./policies.js\\\";\\nimport { hasOwn, normalizeConfig, shouldCanonizeResults } from \\\"./helpers.js\\\";\\nimport { getInMemoryCacheMemoryInternals } from \\\"../../utilities/caching/getMemoryInternals.js\\\";\\nvar InMemoryCache = /** @class */ (function (_super) {\\n    __extends(InMemoryCache, _super);\\n    function InMemoryCache(config) {\\n        if (config === void 0) { config = {}; }\\n        var _this = _super.call(this) || this;\\n        _this.watches = new Set();\\n        _this.addTypenameTransform = new DocumentTransform(addTypenameToDocument);\\n        // Override the default value, since InMemoryCache result objects are frozen\\n        // in development and expected to remain logically immutable in production.\\n        _this.assumeImmutableResults = true;\\n        _this.makeVar = makeVar;\\n        _this.txCount = 0;\\n        _this.config = normalizeConfig(config);\\n        _this.addTypename = !!_this.config.addTypename;\\n        _this.policies = new Policies({\\n            cache: _this,\\n            dataIdFromObject: _this.config.dataIdFromObject,\\n            possibleTypes: _this.config.possibleTypes,\\n            typePolicies: _this.config.typePolicies,\\n        });\\n        _this.init();\\n        return _this;\\n    }\\n    InMemoryCache.prototype.init = function () {\\n        // Passing { resultCaching: false } in the InMemoryCache constructor options\\n        // will completely disable dependency tracking, which will improve memory\\n        // usage but worsen the performance of repeated reads.\\n        var rootStore = (this.data = new EntityStore.Root({\\n            policies: this.policies,\\n            resultCaching: this.config.resultCaching,\\n        }));\\n        // When no optimistic writes are currently active, cache.optimisticData ===\\n        // cache.data, so there are no additional layers on top of the actual data.\\n        // When an optimistic update happens, this.optimisticData will become a\\n        // linked list of EntityStore Layer objects that terminates with the\\n        // original this.data cache object.\\n        this.optimisticData = rootStore.stump;\\n        this.resetResultCache();\\n    };\\n    InMemoryCache.prototype.resetResultCache = function (resetResultIdentities) {\\n        var _this = this;\\n        var previousReader = this.storeReader;\\n        var fragments = this.config.fragments;\\n        // The StoreWriter is mostly stateless and so doesn't really need to be\\n        // reset, but it does need to have its writer.storeReader reference updated,\\n        // so it's simpler to update this.storeWriter as well.\\n        this.storeWriter = new StoreWriter(this, (this.storeReader = new StoreReader({\\n            cache: this,\\n            addTypename: this.addTypename,\\n            resultCacheMaxSize: this.config.resultCacheMaxSize,\\n            canonizeResults: shouldCanonizeResults(this.config),\\n            canon: resetResultIdentities ? void 0 : (previousReader && previousReader.canon),\\n            fragments: fragments,\\n        })), fragments);\\n        this.maybeBroadcastWatch = wrap(function (c, options) {\\n            return _this.broadcastWatch(c, options);\\n        }, {\\n            max: this.config.resultCacheMaxSize ||\\n                cacheSizes[\\\"inMemoryCache.maybeBroadcastWatch\\\"] ||\\n                5000 /* defaultCacheSizes[\\\"inMemoryCache.maybeBroadcastWatch\\\"] */,\\n            makeCacheKey: function (c) {\\n                // Return a cache key (thus enabling result caching) only if we're\\n                // currently using a data store that can track cache dependencies.\\n                var store = c.optimistic ? _this.optimisticData : _this.data;\\n                if (supportsResultCaching(store)) {\\n                    var optimistic = c.optimistic, id = c.id, variables = c.variables;\\n                    return store.makeCacheKey(c.query, \\n                    // Different watches can have the same query, optimistic\\n                    // status, rootId, and variables, but if their callbacks are\\n                    // different, the (identical) result needs to be delivered to\\n                    // each distinct callback. The easiest way to achieve that\\n                    // separation is to include c.callback in the cache key for\\n                    // maybeBroadcastWatch calls. See issue #5733.\\n                    c.callback, canonicalStringify({ optimistic: optimistic, id: id, variables: variables }));\\n                }\\n            },\\n        });\\n        // Since we have thrown away all the cached functions that depend on the\\n        // CacheGroup dependencies maintained by EntityStore, we should also reset\\n        // all CacheGroup dependency information.\\n        new Set([this.data.group, this.optimisticData.group]).forEach(function (group) {\\n            return group.resetCaching();\\n        });\\n    };\\n    InMemoryCache.prototype.restore = function (data) {\\n        this.init();\\n        // Since calling this.init() discards/replaces the entire StoreReader, along\\n        // with the result caches it maintains, this.data.replace(data) won't have\\n        // to bother deleting the old data.\\n        if (data)\\n            this.data.replace(data);\\n        return this;\\n    };\\n    InMemoryCache.prototype.extract = function (optimistic) {\\n        if (optimistic === void 0) { optimistic = false; }\\n        return (optimistic ? this.optimisticData : this.data).extract();\\n    };\\n    InMemoryCache.prototype.read = function (options) {\\n        var \\n        // Since read returns data or null, without any additional metadata\\n        // about whether/where there might have been missing fields, the\\n        // default behavior cannot be returnPartialData = true (like it is\\n        // for the diff method), since defaulting to true would violate the\\n        // integrity of the T in the return type. However, partial data may\\n        // be useful in some cases, so returnPartialData:true may be\\n        // specified explicitly.\\n        _a = options.returnPartialData, \\n        // Since read returns data or null, without any additional metadata\\n        // about whether/where there might have been missing fields, the\\n        // default behavior cannot be returnPartialData = true (like it is\\n        // for the diff method), since defaulting to true would violate the\\n        // integrity of the T in the return type. However, partial data may\\n        // be useful in some cases, so returnPartialData:true may be\\n        // specified explicitly.\\n        returnPartialData = _a === void 0 ? false : _a;\\n        try {\\n            return (this.storeReader.diffQueryAgainstStore(__assign(__assign({}, options), { store: options.optimistic ? this.optimisticData : this.data, config: this.config, returnPartialData: returnPartialData })).result || null);\\n        }\\n        catch (e) {\\n            if (e instanceof MissingFieldError) {\\n                // Swallow MissingFieldError and return null, so callers do not need to\\n                // worry about catching \\\"normal\\\" exceptions resulting from incomplete\\n                // cache data. Unexpected errors will be re-thrown. If you need more\\n                // information about which fields were missing, use cache.diff instead,\\n                // and examine diffResult.missing.\\n                return null;\\n            }\\n            throw e;\\n        }\\n    };\\n    InMemoryCache.prototype.write = function (options) {\\n        try {\\n            ++this.txCount;\\n            return this.storeWriter.writeToStore(this.data, options);\\n        }\\n        finally {\\n            if (!--this.txCount && options.broadcast !== false) {\\n                this.broadcastWatches();\\n            }\\n        }\\n    };\\n    InMemoryCache.prototype.modify = function (options) {\\n        if (hasOwn.call(options, \\\"id\\\") && !options.id) {\\n            // To my knowledge, TypeScript does not currently provide a way to\\n            // enforce that an optional property?:type must *not* be undefined\\n            // when present. That ability would be useful here, because we want\\n            // options.id to default to ROOT_QUERY only when no options.id was\\n            // provided. If the caller attempts to pass options.id with a\\n            // falsy/undefined value (perhaps because cache.identify failed), we\\n            // should not assume the goal was to modify the ROOT_QUERY object.\\n            // We could throw, but it seems natural to return false to indicate\\n            // that nothing was modified.\\n            return false;\\n        }\\n        var store = ((options.optimistic) // Defaults to false.\\n        ) ?\\n            this.optimisticData\\n            : this.data;\\n        try {\\n            ++this.txCount;\\n            return store.modify(options.id || \\\"ROOT_QUERY\\\", options.fields);\\n        }\\n        finally {\\n            if (!--this.txCount && options.broadcast !== false) {\\n                this.broadcastWatches();\\n            }\\n        }\\n    };\\n    InMemoryCache.prototype.diff = function (options) {\\n        return this.storeReader.diffQueryAgainstStore(__assign(__assign({}, options), { store: options.optimistic ? this.optimisticData : this.data, rootId: options.id || \\\"ROOT_QUERY\\\", config: this.config }));\\n    };\\n    InMemoryCache.prototype.watch = function (watch) {\\n        var _this = this;\\n        if (!this.watches.size) {\\n            // In case we previously called forgetCache(this) because\\n            // this.watches became empty (see below), reattach this cache to any\\n            // reactive variables on which it previously depended. It might seem\\n            // paradoxical that we're able to recall something we supposedly\\n            // forgot, but the point of calling forgetCache(this) is to silence\\n            // useless broadcasts while this.watches is empty, and to allow the\\n            // cache to be garbage collected. If, however, we manage to call\\n            // recallCache(this) here, this cache object must not have been\\n            // garbage collected yet, and should resume receiving updates from\\n            // reactive variables, now that it has a watcher to notify.\\n            recallCache(this);\\n        }\\n        this.watches.add(watch);\\n        if (watch.immediate) {\\n            this.maybeBroadcastWatch(watch);\\n        }\\n        return function () {\\n            // Once we remove the last watch from this.watches, cache.broadcastWatches\\n            // no longer does anything, so we preemptively tell the reactive variable\\n            // system to exclude this cache from future broadcasts.\\n            if (_this.watches.delete(watch) && !_this.watches.size) {\\n                forgetCache(_this);\\n            }\\n            // Remove this watch from the LRU cache managed by the\\n            // maybeBroadcastWatch OptimisticWrapperFunction, to prevent memory\\n            // leaks involving the closure of watch.callback.\\n            _this.maybeBroadcastWatch.forget(watch);\\n        };\\n    };\\n    InMemoryCache.prototype.gc = function (options) {\\n        var _a;\\n        canonicalStringify.reset();\\n        print.reset();\\n        this.addTypenameTransform.resetCache();\\n        (_a = this.config.fragments) === null || _a === void 0 ? void 0 : _a.resetCaches();\\n        var ids = this.optimisticData.gc();\\n        if (options && !this.txCount) {\\n            if (options.resetResultCache) {\\n                this.resetResultCache(options.resetResultIdentities);\\n            }\\n            else if (options.resetResultIdentities) {\\n                this.storeReader.resetCanon();\\n            }\\n        }\\n        return ids;\\n    };\\n    // Call this method to ensure the given root ID remains in the cache after\\n    // garbage collection, along with its transitive child entities. Note that\\n    // the cache automatically retains all directly written entities. By default,\\n    // the retainment persists after optimistic updates are removed. Pass true\\n    // for the optimistic argument if you would prefer for the retainment to be\\n    // discarded when the top-most optimistic layer is removed. Returns the\\n    // resulting (non-negative) retainment count.\\n    InMemoryCache.prototype.retain = function (rootId, optimistic) {\\n        return (optimistic ? this.optimisticData : this.data).retain(rootId);\\n    };\\n    // Call this method to undo the effect of the retain method, above. Once the\\n    // retainment count falls to zero, the given ID will no longer be preserved\\n    // during garbage collection, though it may still be preserved by other safe\\n    // entities that refer to it. Returns the resulting (non-negative) retainment\\n    // count, in case that's useful.\\n    InMemoryCache.prototype.release = function (rootId, optimistic) {\\n        return (optimistic ? this.optimisticData : this.data).release(rootId);\\n    };\\n    // Returns the canonical ID for a given StoreObject, obeying typePolicies\\n    // and keyFields (and dataIdFromObject, if you still use that). At minimum,\\n    // the object must contain a __typename and any primary key fields required\\n    // to identify entities of that type. If you pass a query result object, be\\n    // sure that none of the primary key fields have been renamed by aliasing.\\n    // If you pass a Reference object, its __ref ID string will be returned.\\n    InMemoryCache.prototype.identify = function (object) {\\n        if (isReference(object))\\n            return object.__ref;\\n        try {\\n            return this.policies.identify(object)[0];\\n        }\\n        catch (e) {\\n            globalThis.__DEV__ !== false && invariant.warn(e);\\n        }\\n    };\\n    InMemoryCache.prototype.evict = function (options) {\\n        if (!options.id) {\\n            if (hasOwn.call(options, \\\"id\\\")) {\\n                // See comment in modify method about why we return false when\\n                // options.id exists but is falsy/undefined.\\n                return false;\\n            }\\n            options = __assign(__assign({}, options), { id: \\\"ROOT_QUERY\\\" });\\n        }\\n        try {\\n            // It's unlikely that the eviction will end up invoking any other\\n            // cache update operations while it's running, but {in,de}crementing\\n            // this.txCount still seems like a good idea, for uniformity with\\n            // the other update methods.\\n            ++this.txCount;\\n            // Pass this.data as a limit on the depth of the eviction, so evictions\\n            // during optimistic updates (when this.data is temporarily set equal to\\n            // this.optimisticData) do not escape their optimistic Layer.\\n            return this.optimisticData.evict(options, this.data);\\n        }\\n        finally {\\n            if (!--this.txCount && options.broadcast !== false) {\\n                this.broadcastWatches();\\n            }\\n        }\\n    };\\n    InMemoryCache.prototype.reset = function (options) {\\n        var _this = this;\\n        this.init();\\n        canonicalStringify.reset();\\n        if (options && options.discardWatches) {\\n            // Similar to what happens in the unsubscribe function returned by\\n            // cache.watch, applied to all current watches.\\n            this.watches.forEach(function (watch) { return _this.maybeBroadcastWatch.forget(watch); });\\n            this.watches.clear();\\n            forgetCache(this);\\n        }\\n        else {\\n            // Calling this.init() above unblocks all maybeBroadcastWatch caching, so\\n            // this.broadcastWatches() triggers a broadcast to every current watcher\\n            // (letting them know their data is now missing). This default behavior is\\n            // convenient because it means the watches do not have to be manually\\n            // reestablished after resetting the cache. To prevent this broadcast and\\n            // cancel all watches, pass true for options.discardWatches.\\n            this.broadcastWatches();\\n        }\\n        return Promise.resolve();\\n    };\\n    InMemoryCache.prototype.removeOptimistic = function (idToRemove) {\\n        var newOptimisticData = this.optimisticData.removeLayer(idToRemove);\\n        if (newOptimisticData !== this.optimisticData) {\\n            this.optimisticData = newOptimisticData;\\n            this.broadcastWatches();\\n        }\\n    };\\n    InMemoryCache.prototype.batch = function (options) {\\n        var _this = this;\\n        var update = options.update, _a = options.optimistic, optimistic = _a === void 0 ? true : _a, removeOptimistic = options.removeOptimistic, onWatchUpdated = options.onWatchUpdated;\\n        var updateResult;\\n        var perform = function (layer) {\\n            var _a = _this, data = _a.data, optimisticData = _a.optimisticData;\\n            ++_this.txCount;\\n            if (layer) {\\n                _this.data = _this.optimisticData = layer;\\n            }\\n            try {\\n                return (updateResult = update(_this));\\n            }\\n            finally {\\n                --_this.txCount;\\n                _this.data = data;\\n                _this.optimisticData = optimisticData;\\n            }\\n        };\\n        var alreadyDirty = new Set();\\n        if (onWatchUpdated && !this.txCount) {\\n            // If an options.onWatchUpdated callback is provided, we want to call it\\n            // with only the Cache.WatchOptions objects affected by options.update,\\n            // but there might be dirty watchers already waiting to be broadcast that\\n            // have nothing to do with the update. To prevent including those watchers\\n            // in the post-update broadcast, we perform this initial broadcast to\\n            // collect the dirty watchers, so we can re-dirty them later, after the\\n            // post-update broadcast, allowing them to receive their pending\\n            // broadcasts the next time broadcastWatches is called, just as they would\\n            // if we never called cache.batch.\\n            this.broadcastWatches(__assign(__assign({}, options), { onWatchUpdated: function (watch) {\\n                    alreadyDirty.add(watch);\\n                    return false;\\n                } }));\\n        }\\n        if (typeof optimistic === \\\"string\\\") {\\n            // Note that there can be multiple layers with the same optimistic ID.\\n            // When removeOptimistic(id) is called for that id, all matching layers\\n            // will be removed, and the remaining layers will be reapplied.\\n            this.optimisticData = this.optimisticData.addLayer(optimistic, perform);\\n        }\\n        else if (optimistic === false) {\\n            // Ensure both this.data and this.optimisticData refer to the root\\n            // (non-optimistic) layer of the cache during the update. Note that\\n            // this.data could be a Layer if we are currently executing an optimistic\\n            // update function, but otherwise will always be an EntityStore.Root\\n            // instance.\\n            perform(this.data);\\n        }\\n        else {\\n            // Otherwise, leave this.data and this.optimisticData unchanged and run\\n            // the update with broadcast batching.\\n            perform();\\n        }\\n        if (typeof removeOptimistic === \\\"string\\\") {\\n            this.optimisticData = this.optimisticData.removeLayer(removeOptimistic);\\n        }\\n        // Note: if this.txCount > 0, then alreadyDirty.size === 0, so this code\\n        // takes the else branch and calls this.broadcastWatches(options), which\\n        // does nothing when this.txCount > 0.\\n        if (onWatchUpdated && alreadyDirty.size) {\\n            this.broadcastWatches(__assign(__assign({}, options), { onWatchUpdated: function (watch, diff) {\\n                    var result = onWatchUpdated.call(this, watch, diff);\\n                    if (result !== false) {\\n                        // Since onWatchUpdated did not return false, this diff is\\n                        // about to be broadcast to watch.callback, so we don't need\\n                        // to re-dirty it with the other alreadyDirty watches below.\\n                        alreadyDirty.delete(watch);\\n                    }\\n                    return result;\\n                } }));\\n            // Silently re-dirty any watches that were already dirty before the update\\n            // was performed, and were not broadcast just now.\\n            if (alreadyDirty.size) {\\n                alreadyDirty.forEach(function (watch) { return _this.maybeBroadcastWatch.dirty(watch); });\\n            }\\n        }\\n        else {\\n            // If alreadyDirty is empty or we don't have an onWatchUpdated\\n            // function, we don't need to go to the trouble of wrapping\\n            // options.onWatchUpdated.\\n            this.broadcastWatches(options);\\n        }\\n        return updateResult;\\n    };\\n    InMemoryCache.prototype.performTransaction = function (update, optimisticId) {\\n        return this.batch({\\n            update: update,\\n            optimistic: optimisticId || optimisticId !== null,\\n        });\\n    };\\n    InMemoryCache.prototype.transformDocument = function (document) {\\n        return this.addTypenameToDocument(this.addFragmentsToDocument(document));\\n    };\\n    InMemoryCache.prototype.broadcastWatches = function (options) {\\n        var _this = this;\\n        if (!this.txCount) {\\n            this.watches.forEach(function (c) { return _this.maybeBroadcastWatch(c, options); });\\n        }\\n    };\\n    InMemoryCache.prototype.addFragmentsToDocument = function (document) {\\n        var fragments = this.config.fragments;\\n        return fragments ? fragments.transform(document) : document;\\n    };\\n    InMemoryCache.prototype.addTypenameToDocument = function (document) {\\n        if (this.addTypename) {\\n            return this.addTypenameTransform.transformDocument(document);\\n        }\\n        return document;\\n    };\\n    // This method is wrapped by maybeBroadcastWatch, which is called by\\n    // broadcastWatches, so that we compute and broadcast results only when\\n    // the data that would be broadcast might have changed. It would be\\n    // simpler to check for changes after recomputing a result but before\\n    // broadcasting it, but this wrapping approach allows us to skip both\\n    // the recomputation and the broadcast, in most cases.\\n    InMemoryCache.prototype.broadcastWatch = function (c, options) {\\n        var lastDiff = c.lastDiff;\\n        // Both WatchOptions and DiffOptions extend ReadOptions, and DiffOptions\\n        // currently requires no additional properties, so we can use c (a\\n        // WatchOptions object) as DiffOptions, without having to allocate a new\\n        // object, and without having to enumerate the relevant properties (query,\\n        // variables, etc.) explicitly. There will be some additional properties\\n        // (lastDiff, callback, etc.), but cache.diff ignores them.\\n        var diff = this.diff(c);\\n        if (options) {\\n            if (c.optimistic && typeof options.optimistic === \\\"string\\\") {\\n                diff.fromOptimisticTransaction = true;\\n            }\\n            if (options.onWatchUpdated &&\\n                options.onWatchUpdated.call(this, c, diff, lastDiff) === false) {\\n                // Returning false from the onWatchUpdated callback will prevent\\n                // calling c.callback(diff) for this watcher.\\n                return;\\n            }\\n        }\\n        if (!lastDiff || !equal(lastDiff.result, diff.result)) {\\n            c.callback((c.lastDiff = diff), lastDiff);\\n        }\\n    };\\n    return InMemoryCache;\\n}(ApolloCache));\\nexport { InMemoryCache };\\nif (globalThis.__DEV__ !== false) {\\n    InMemoryCache.prototype.getMemoryInternals = getInMemoryCacheMemoryInternals;\\n}\\n//# sourceMappingURL=inMemoryCache.js.map\"],\n  \"mappings\": \"AAAA,SAAS,UAAU,iBAAiB;AACpC,SAAS,iBAAiB;AAE1B,OAAO;AACP,SAAS,YAAY;AACrB,SAAS,aAAa;AACtB,SAAS,mBAAmB;AAC5B,SAAS,yBAAyB;AAClC,SAAS,uBAAuB,aAAa,mBAAmB,oBAAoB,OAAO,kBAAmB;AAC9G,SAAS,mBAAmB;AAC5B,SAAS,mBAAmB;AAC5B,SAAS,aAAa,6BAA6B;AACnD,SAAS,SAAS,aAAa,mBAAmB;AAClD,SAAS,gBAAgB;AACzB,SAAS,QAAQ,iBAAiB,6BAA6B;AAC/D,SAAS,uCAAuC;AAChD,IAAI;AAAA;AAAA,EAA+B,SAAU,QAAQ;AACjD,cAAUA,gBAAe,MAAM;AAC/B,aAASA,eAAc,QAAQ;AAC3B,UAAI,WAAW,QAAQ;AAAE,iBAAS,CAAC;AAAA,MAAG;AACtC,UAAI,QAAQ,OAAO,KAAK,IAAI,KAAK;AACjC,YAAM,UAAU,oBAAI,IAAI;AACxB,YAAM,uBAAuB,IAAI,kBAAkB,qBAAqB;AAGxE,YAAM,yBAAyB;AAC/B,YAAM,UAAU;AAChB,YAAM,UAAU;AAChB,YAAM,SAAS,gBAAgB,MAAM;AACrC,YAAM,cAAc,CAAC,CAAC,MAAM,OAAO;AACnC,YAAM,WAAW,IAAI,SAAS;AAAA,QAC1B,OAAO;AAAA,QACP,kBAAkB,MAAM,OAAO;AAAA,QAC/B,eAAe,MAAM,OAAO;AAAA,QAC5B,cAAc,MAAM,OAAO;AAAA,MAC/B,CAAC;AACD,YAAM,KAAK;AACX,aAAO;AAAA,IACX;AACA,IAAAA,eAAc,UAAU,OAAO,WAAY;AAIvC,UAAI,YAAa,KAAK,OAAO,IAAI,YAAY,KAAK;AAAA,QAC9C,UAAU,KAAK;AAAA,QACf,eAAe,KAAK,OAAO;AAAA,MAC/B,CAAC;AAMD,WAAK,iBAAiB,UAAU;AAChC,WAAK,iBAAiB;AAAA,IAC1B;AACA,IAAAA,eAAc,UAAU,mBAAmB,SAAU,uBAAuB;AACxE,UAAI,QAAQ;AACZ,UAAI,iBAAiB,KAAK;AAC1B,UAAI,YAAY,KAAK,OAAO;AAI5B,WAAK,cAAc,IAAI,YAAY,MAAO,KAAK,cAAc,IAAI,YAAY;AAAA,QACzE,OAAO;AAAA,QACP,aAAa,KAAK;AAAA,QAClB,oBAAoB,KAAK,OAAO;AAAA,QAChC,iBAAiB,sBAAsB,KAAK,MAAM;AAAA,QAClD,OAAO,wBAAwB,SAAU,kBAAkB,eAAe;AAAA,QAC1E;AAAA,MACJ,CAAC,GAAI,SAAS;AACd,WAAK,sBAAsB,KAAK,SAAU,GAAG,SAAS;AAClD,eAAO,MAAM,eAAe,GAAG,OAAO;AAAA,MAC1C,GAAG;AAAA,QACC,KAAK,KAAK,OAAO,sBACb,WAAW,mCAAmC,KAC9C;AAAA,QACJ,cAAc,SAAU,GAAG;AAGvB,cAAI,QAAQ,EAAE,aAAa,MAAM,iBAAiB,MAAM;AACxD,cAAI,sBAAsB,KAAK,GAAG;AAC9B,gBAAI,aAAa,EAAE,YAAY,KAAK,EAAE,IAAI,YAAY,EAAE;AACxD,mBAAO,MAAM;AAAA,cAAa,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAO5B,EAAE;AAAA,cAAU,mBAAmB,EAAE,YAAwB,IAAQ,UAAqB,CAAC;AAAA,YAAC;AAAA,UAC5F;AAAA,QACJ;AAAA,MACJ,CAAC;AAID,2BAAI,IAAI,CAAC,KAAK,KAAK,OAAO,KAAK,eAAe,KAAK,CAAC,GAAE,QAAQ,SAAU,OAAO;AAC3E,eAAO,MAAM,aAAa;AAAA,MAC9B,CAAC;AAAA,IACL;AACA,IAAAA,eAAc,UAAU,UAAU,SAAU,MAAM;AAC9C,WAAK,KAAK;AAIV,UAAI;AACA,aAAK,KAAK,QAAQ,IAAI;AAC1B,aAAO;AAAA,IACX;AACA,IAAAA,eAAc,UAAU,UAAU,SAAU,YAAY;AACpD,UAAI,eAAe,QAAQ;AAAE,qBAAa;AAAA,MAAO;AACjD,cAAQ,aAAa,KAAK,iBAAiB,KAAK,MAAM,QAAQ;AAAA,IAClE;AACA,IAAAA,eAAc,UAAU,OAAO,SAAU,SAAS;AAC9C,UAQA,KAAK,QAAQ,mBAQb,oBAAoB,OAAO,SAAS,QAAQ;AAC5C,UAAI;AACA,eAAQ,KAAK,YAAY,sBAAsB,SAAS,SAAS,CAAC,GAAG,OAAO,GAAG,EAAE,OAAO,QAAQ,aAAa,KAAK,iBAAiB,KAAK,MAAM,QAAQ,KAAK,QAAQ,kBAAqC,CAAC,CAAC,EAAE,UAAU;AAAA,MAC1N,SACO,GAAG;AACN,YAAI,aAAa,mBAAmB;AAMhC,iBAAO;AAAA,QACX;AACA,cAAM;AAAA,MACV;AAAA,IACJ;AACA,IAAAA,eAAc,UAAU,QAAQ,SAAU,SAAS;AAC/C,UAAI;AACA,UAAE,KAAK;AACP,eAAO,KAAK,YAAY,aAAa,KAAK,MAAM,OAAO;AAAA,MAC3D,UACA;AACI,YAAI,CAAC,EAAE,KAAK,WAAW,QAAQ,cAAc,OAAO;AAChD,eAAK,iBAAiB;AAAA,QAC1B;AAAA,MACJ;AAAA,IACJ;AACA,IAAAA,eAAc,UAAU,SAAS,SAAU,SAAS;AAChD,UAAI,OAAO,KAAK,SAAS,IAAI,KAAK,CAAC,QAAQ,IAAI;AAU3C,eAAO;AAAA,MACX;AACA,UAAI,QAAU,QAAQ,aAElB,KAAK,iBACH,KAAK;AACX,UAAI;AACA,UAAE,KAAK;AACP,eAAO,MAAM,OAAO,QAAQ,MAAM,cAAc,QAAQ,MAAM;AAAA,MAClE,UACA;AACI,YAAI,CAAC,EAAE,KAAK,WAAW,QAAQ,cAAc,OAAO;AAChD,eAAK,iBAAiB;AAAA,QAC1B;AAAA,MACJ;AAAA,IACJ;AACA,IAAAA,eAAc,UAAU,OAAO,SAAU,SAAS;AAC9C,aAAO,KAAK,YAAY,sBAAsB,SAAS,SAAS,CAAC,GAAG,OAAO,GAAG,EAAE,OAAO,QAAQ,aAAa,KAAK,iBAAiB,KAAK,MAAM,QAAQ,QAAQ,MAAM,cAAc,QAAQ,KAAK,OAAO,CAAC,CAAC;AAAA,IAC3M;AACA,IAAAA,eAAc,UAAU,QAAQ,SAAU,OAAO;AAC7C,UAAI,QAAQ;AACZ,UAAI,CAAC,KAAK,QAAQ,MAAM;AAWpB,oBAAY,IAAI;AAAA,MACpB;AACA,WAAK,QAAQ,IAAI,KAAK;AACtB,UAAI,MAAM,WAAW;AACjB,aAAK,oBAAoB,KAAK;AAAA,MAClC;AACA,aAAO,WAAY;AAIf,YAAI,MAAM,QAAQ,OAAO,KAAK,KAAK,CAAC,MAAM,QAAQ,MAAM;AACpD,sBAAY,KAAK;AAAA,QACrB;AAIA,cAAM,oBAAoB,OAAO,KAAK;AAAA,MAC1C;AAAA,IACJ;AACA,IAAAA,eAAc,UAAU,KAAK,SAAU,SAAS;AAC5C,UAAI;AACJ,yBAAmB,MAAM;AACzB,YAAM,MAAM;AACZ,WAAK,qBAAqB,WAAW;AACrC,OAAC,KAAK,KAAK,OAAO,eAAe,QAAQ,OAAO,SAAS,SAAS,GAAG,YAAY;AACjF,UAAI,MAAM,KAAK,eAAe,GAAG;AACjC,UAAI,WAAW,CAAC,KAAK,SAAS;AAC1B,YAAI,QAAQ,kBAAkB;AAC1B,eAAK,iBAAiB,QAAQ,qBAAqB;AAAA,QACvD,WACS,QAAQ,uBAAuB;AACpC,eAAK,YAAY,WAAW;AAAA,QAChC;AAAA,MACJ;AACA,aAAO;AAAA,IACX;AAQA,IAAAA,eAAc,UAAU,SAAS,SAAU,QAAQ,YAAY;AAC3D,cAAQ,aAAa,KAAK,iBAAiB,KAAK,MAAM,OAAO,MAAM;AAAA,IACvE;AAMA,IAAAA,eAAc,UAAU,UAAU,SAAU,QAAQ,YAAY;AAC5D,cAAQ,aAAa,KAAK,iBAAiB,KAAK,MAAM,QAAQ,MAAM;AAAA,IACxE;AAOA,IAAAA,eAAc,UAAU,WAAW,SAAU,QAAQ;AACjD,UAAI,YAAY,MAAM;AAClB,eAAO,OAAO;AAClB,UAAI;AACA,eAAO,KAAK,SAAS,SAAS,MAAM,EAAE,CAAC;AAAA,MAC3C,SACO,GAAG;AACN,mBAAW,YAAY,SAAS,UAAU,KAAK,CAAC;AAAA,MACpD;AAAA,IACJ;AACA,IAAAA,eAAc,UAAU,QAAQ,SAAU,SAAS;AAC/C,UAAI,CAAC,QAAQ,IAAI;AACb,YAAI,OAAO,KAAK,SAAS,IAAI,GAAG;AAG5B,iBAAO;AAAA,QACX;AACA,kBAAU,SAAS,SAAS,CAAC,GAAG,OAAO,GAAG,EAAE,IAAI,aAAa,CAAC;AAAA,MAClE;AACA,UAAI;AAKA,UAAE,KAAK;AAIP,eAAO,KAAK,eAAe,MAAM,SAAS,KAAK,IAAI;AAAA,MACvD,UACA;AACI,YAAI,CAAC,EAAE,KAAK,WAAW,QAAQ,cAAc,OAAO;AAChD,eAAK,iBAAiB;AAAA,QAC1B;AAAA,MACJ;AAAA,IACJ;AACA,IAAAA,eAAc,UAAU,QAAQ,SAAU,SAAS;AAC/C,UAAI,QAAQ;AACZ,WAAK,KAAK;AACV,yBAAmB,MAAM;AACzB,UAAI,WAAW,QAAQ,gBAAgB;AAGnC,aAAK,QAAQ,QAAQ,SAAU,OAAO;AAAE,iBAAO,MAAM,oBAAoB,OAAO,KAAK;AAAA,QAAG,CAAC;AACzF,aAAK,QAAQ,MAAM;AACnB,oBAAY,IAAI;AAAA,MACpB,OACK;AAOD,aAAK,iBAAiB;AAAA,MAC1B;AACA,aAAO,QAAQ,QAAQ;AAAA,IAC3B;AACA,IAAAA,eAAc,UAAU,mBAAmB,SAAU,YAAY;AAC7D,UAAI,oBAAoB,KAAK,eAAe,YAAY,UAAU;AAClE,UAAI,sBAAsB,KAAK,gBAAgB;AAC3C,aAAK,iBAAiB;AACtB,aAAK,iBAAiB;AAAA,MAC1B;AAAA,IACJ;AACA,IAAAA,eAAc,UAAU,QAAQ,SAAU,SAAS;AAC/C,UAAI,QAAQ;AACZ,UAAI,SAAS,QAAQ,QAAQ,KAAK,QAAQ,YAAY,aAAa,OAAO,SAAS,OAAO,IAAI,mBAAmB,QAAQ,kBAAkB,iBAAiB,QAAQ;AACpK,UAAI;AACJ,UAAI,UAAU,SAAU,OAAO;AAC3B,YAAIC,MAAK,OAAO,OAAOA,IAAG,MAAM,iBAAiBA,IAAG;AACpD,UAAE,MAAM;AACR,YAAI,OAAO;AACP,gBAAM,OAAO,MAAM,iBAAiB;AAAA,QACxC;AACA,YAAI;AACA,iBAAQ,eAAe,OAAO,KAAK;AAAA,QACvC,UACA;AACI,YAAE,MAAM;AACR,gBAAM,OAAO;AACb,gBAAM,iBAAiB;AAAA,QAC3B;AAAA,MACJ;AACA,UAAI,eAAe,oBAAI,IAAI;AAC3B,UAAI,kBAAkB,CAAC,KAAK,SAAS;AAUjC,aAAK,iBAAiB,SAAS,SAAS,CAAC,GAAG,OAAO,GAAG,EAAE,gBAAgB,SAAU,OAAO;AACjF,uBAAa,IAAI,KAAK;AACtB,iBAAO;AAAA,QACX,EAAE,CAAC,CAAC;AAAA,MACZ;AACA,UAAI,OAAO,eAAe,UAAU;AAIhC,aAAK,iBAAiB,KAAK,eAAe,SAAS,YAAY,OAAO;AAAA,MAC1E,WACS,eAAe,OAAO;AAM3B,gBAAQ,KAAK,IAAI;AAAA,MACrB,OACK;AAGD,gBAAQ;AAAA,MACZ;AACA,UAAI,OAAO,qBAAqB,UAAU;AACtC,aAAK,iBAAiB,KAAK,eAAe,YAAY,gBAAgB;AAAA,MAC1E;AAIA,UAAI,kBAAkB,aAAa,MAAM;AACrC,aAAK,iBAAiB,SAAS,SAAS,CAAC,GAAG,OAAO,GAAG,EAAE,gBAAgB,SAAU,OAAO,MAAM;AACvF,cAAI,SAAS,eAAe,KAAK,MAAM,OAAO,IAAI;AAClD,cAAI,WAAW,OAAO;AAIlB,yBAAa,OAAO,KAAK;AAAA,UAC7B;AACA,iBAAO;AAAA,QACX,EAAE,CAAC,CAAC;AAGR,YAAI,aAAa,MAAM;AACnB,uBAAa,QAAQ,SAAU,OAAO;AAAE,mBAAO,MAAM,oBAAoB,MAAM,KAAK;AAAA,UAAG,CAAC;AAAA,QAC5F;AAAA,MACJ,OACK;AAID,aAAK,iBAAiB,OAAO;AAAA,MACjC;AACA,aAAO;AAAA,IACX;AACA,IAAAD,eAAc,UAAU,qBAAqB,SAAU,QAAQ,cAAc;AACzE,aAAO,KAAK,MAAM;AAAA,QACd;AAAA,QACA,YAAY,gBAAgB,iBAAiB;AAAA,MACjD,CAAC;AAAA,IACL;AACA,IAAAA,eAAc,UAAU,oBAAoB,SAAU,UAAU;AAC5D,aAAO,KAAK,sBAAsB,KAAK,uBAAuB,QAAQ,CAAC;AAAA,IAC3E;AACA,IAAAA,eAAc,UAAU,mBAAmB,SAAU,SAAS;AAC1D,UAAI,QAAQ;AACZ,UAAI,CAAC,KAAK,SAAS;AACf,aAAK,QAAQ,QAAQ,SAAU,GAAG;AAAE,iBAAO,MAAM,oBAAoB,GAAG,OAAO;AAAA,QAAG,CAAC;AAAA,MACvF;AAAA,IACJ;AACA,IAAAA,eAAc,UAAU,yBAAyB,SAAU,UAAU;AACjE,UAAI,YAAY,KAAK,OAAO;AAC5B,aAAO,YAAY,UAAU,UAAU,QAAQ,IAAI;AAAA,IACvD;AACA,IAAAA,eAAc,UAAU,wBAAwB,SAAU,UAAU;AAChE,UAAI,KAAK,aAAa;AAClB,eAAO,KAAK,qBAAqB,kBAAkB,QAAQ;AAAA,MAC/D;AACA,aAAO;AAAA,IACX;AAOA,IAAAA,eAAc,UAAU,iBAAiB,SAAU,GAAG,SAAS;AAC3D,UAAI,WAAW,EAAE;AAOjB,UAAI,OAAO,KAAK,KAAK,CAAC;AACtB,UAAI,SAAS;AACT,YAAI,EAAE,cAAc,OAAO,QAAQ,eAAe,UAAU;AACxD,eAAK,4BAA4B;AAAA,QACrC;AACA,YAAI,QAAQ,kBACR,QAAQ,eAAe,KAAK,MAAM,GAAG,MAAM,QAAQ,MAAM,OAAO;AAGhE;AAAA,QACJ;AAAA,MACJ;AACA,UAAI,CAAC,YAAY,CAAC,MAAM,SAAS,QAAQ,KAAK,MAAM,GAAG;AACnD,UAAE,SAAU,EAAE,WAAW,MAAO,QAAQ;AAAA,MAC5C;AAAA,IACJ;AACA,WAAOA;AAAA,EACX,EAAE,WAAW;AAAA;AACb,SAAS;AACT,IAAI,WAAW,YAAY,OAAO;AAC9B,gBAAc,UAAU,qBAAqB;AACjD;\",\n  \"names\": [\"InMemoryCache\", \"_a\"]\n}\n"
    },
    {
      "name": "vite:css-post",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "normal"
    },
    {
      "name": "vite:build-html",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "normal"
    },
    {
      "name": "vite:worker-import-meta-url",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "normal"
    },
    {
      "name": "vite:asset-import-meta-url",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "normal"
    },
    {
      "name": "commonjs",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "normal"
    },
    {
      "name": "vite:dynamic-import-vars",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "normal"
    },
    {
      "name": "vite:import-glob",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "normal"
    },
    {
      "name": "nuxt:composable-keys",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "post"
    },
    {
      "name": "nuxt:composable-keys",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "post"
    },
    {
      "name": "nuxt:imports-transform",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "post"
    },
    {
      "name": "nuxt:imports-transform",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "post"
    },
    {
      "name": "unctx:transform",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "post"
    },
    {
      "name": "unctx:transform",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "post"
    },
    {
      "name": "nuxt:pages-macros-transform",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "post"
    },
    {
      "name": "nuxt:pages-macros-transform",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "post"
    },
    {
      "name": "nuxt:tree-shake-template",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "post"
    },
    {
      "name": "nuxt:components-loader",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "post"
    },
    {
      "name": "nuxt:tree-shake-composables:transform",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "post"
    },
    {
      "name": "vite:build-import-analysis",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "normal"
    },
    {
      "name": "vite:reporter",
      "start": 1713304787101,
      "end": 1713304787101,
      "order": "normal"
    }
  ]
}
